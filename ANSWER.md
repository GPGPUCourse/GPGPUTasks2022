# Решения задач

### Задача 1
Проще и быстрее будет реализовать сигнал `y1`. Дело в том, что вычисление значения
каждого элемента сигнала `y1[i]` не зависит от значений других элементов
`y1[j]`, поэтому все элементы `y1` будут считаться параллельно и независимо.

Для вычисления же значения элемента сигнала `y2[i]` необходимо,  чтобы
были уже посчитаны два предыдущих элемента `y2[i - 1]` и `y2[i - 2]`. А
следовательно элементы `y2` не могут считаться параллельно и независимо,
их расчеты придется синхронизировать так, чтобы `y2[i]` считался только
после того, как посчитаны два предыдущих элемента. Возможно, есть
какие-то способы эффективно делать эту синхронизацию, возможно формулу
расчета элементов `y2` можно преобразовать к нерекурсивной и за счет
этого сделать какие-то оптимизации. Но в любом случаи это всё требует
дополнительных усилий и реализовать подобное будет не проще и не быстрее,
чем расчет сигнала `y1`.

### Задача 2
Из условия 
> рабочая группа делится на warp/wavefront-ы таким образом что внутри 
warp/wavefront номер WorkItem по оси x меняется чаще всего, затем по
оси y и затем по оси z.

а также размера warp-а следует, что в одном warp-е вычисляются WorkItem-ы
с одинаковыми координатами y, z, но различными x. 

Т.к. нам дана формула
```
int idx = get_local_id(1) + get_local_size(1) * get_local_id(0);
```
и `get_local_size(1) == 32`, слагаемое `get_local_size(1) * get_local_id(0)`
не влияет на значение `idx % 32`, т.к. оно кратно 32. Поэтому
`idx % 32 == get_local_id(1) % 32`. А т.к. `get_local_id(1)` (т.е. координата
y) в рамках одного warp-а не меняется, значение `idx % 32` в рамках одного
warp-а будет всегда одинаково. Поэтому все потоки одного warp-а будут заходить
в одну ветку условного оператора, а значит code divergence не произойдет.

### Задача 3
По аналогичным причинам, описанным в решении задачи 2, одном warp-е вычисляются WorkItem-ы
с одинаковыми координатами y, z, но различными x.
#### Пункт (a)
В рамках одного warp-а `get_local_size(0) * get_local_id(1)` будет одинаковым,
а также кратным 32. Поэтому указатель `data + get_local_size(0) * get_local_id(1) % 128 == 0`,
т.к. `sizeof(float) == 4`, а указатель `data` выравнен.

При этом `get_local_id(0)` будет меняться от 0 до 31 в рамках одного warp-а.
Поэтому все обращения `data[get_local_id(0) + get_local_size(0) * get_local_id(1)]` в
рамках одного warp-а будут записывать данные в рамках одной кеш линии, а следовательно
будут склеены (coalesced).

В рамках одного warp-а будет происходить 1 кеш линий запись. Вся рабочая
группа делится на 32 warp-а, поэтому произойдет 32 кеш линий записей.

#### Пункт (b)
В рамках одного warp-а `get_local_id(1)` не меняется. При этом у каждого
у каждого потока одного warp-а будет своё значение `get_local_size(1) * get_local_id(0)`,
т.к. `get_local_id(0)` у каждого потока свой. Причем т.к. `get_local_size(1) == 32`
обращения `data[get_local_id(1) + get_local_size(1) * get_local_id(0)]` будут
записывать данные в рамках разных кеш линий. Поэтому в рамках одного warp-а
будет происходить 32 кеш линий записи. А т.к. склеивание запросов происходит
только в рамках одного warp-а, каждый warp будет делать свои 32 кеш линий
записи, а значит всего в рамках одной рабочей группы будет происходить
`32 * 32 = 1024` кеш линий записи (в одной рабочей группе 32 warp-а).

### Пункт (c)
Он похож на пункт (a), но здесь есть сдвиг указателя `data` на один элемент
вперед (т.е. на 4 байта вперед). Поэтому в рамках одного warp-а записи в
потоках с `get_local_id(0) in 0..30` склеятся и будут происходить в
рамках одной кеш линии, а в потоке с `get_local_id(0) == 31` -- уже в другой кеш линии.
Поэтому в одном warp-е будет 2 кеш линий записи. А в рамках рабочей группы
будет `2 * 32 = 64` кеш линий записи.