## 1

Первое тривиально реализуется, почти как A+B. Второе сложнее и менее эффективно. Разница в том, что каждое y1[i] зависит от константного количества входных переменных, а во y2[i] &mdash; от i входных переменных.

#### Бонус: набросок алгоритма для y2

Рекурренту можно выразить через умножение вектора на матрицу
```math
\begin{pmatrix}y_n \\ y_{n-1} \\ 1\end{pmatrix} = 
A_n
\begin{pmatrix}y_{n-1} \\ y_{n-2} \\ 1\end{pmatrix} =
B_n
\begin{pmatrix}y_2 \\ y_1 \\ 1\end{pmatrix},
```
где
```math
A_n = \begin{pmatrix}1 & 1 & x_n \\ 1 & 0 & 0 \\ 0 & 0 & 1\end{pmatrix},\\
\\
B_n = A_3\cdot A_4\cdot ... \cdot A_n.
```
Получается, надо научиться параллельно считать частичные произведения для последовательности матриц. В курсе параллельных алгоритмов такая операция называлась scan. Она может быть реализована на GPU со span $O(\log^2 n)$.

## 2

`idx == get_local_id(1) + 32 * get_local_id(0)`

`idx % 32 == get_local_id(1)`

По условию внутри warp сначала меняется x. Так как размер warp'а равен `get_local_size(0)`, y и z будут одинаковы для всех потоков warp'а. То есть code divergence не произойдёт.

## 3

(a) Да, будет.

`32*32*sizeof(float)/128 = 32` кеш-линии.

(b) Нет, не будет.

В каждом варпе происходит запись в 32 кеш-линии. Итого, `32*32 = 1024` кеш-линии.

(c) Каждый warp будет писать в 2 кеш-линии (31 поток в одну и 1 в другую). Итого, `2*32 = 64` кеш-линии.

Считается ли это coalesced, я не понял.